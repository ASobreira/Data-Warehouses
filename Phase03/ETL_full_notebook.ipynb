{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3 - ETL System"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Grupo 1\n",
    "    - Tiago Rodrigues (49593)\n",
    "    - Ivo Oliveira (50301)\n",
    "    - Martim Silva (51304)\n",
    "    - Alexandre Sobreira (59451)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and Librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2 as pg\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(date):\n",
    "    if date.month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif date.month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif date.month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    else:\n",
    "        return 'Autumn'\n",
    "    \n",
    "def get_semester(date):\n",
    "    if date.month in [1, 2, 3, 4, 5, 6]:\n",
    "        return '1'\n",
    "    else:\n",
    "        return '2' \n",
    "\n",
    "def get_weekend_indicator(day_of_week):\n",
    "    if day_of_week < 5:\n",
    "        return 'Non-Weekend'\n",
    "    else:\n",
    "        return 'Weekend'\n",
    "    \n",
    "def get_holiday_indicator(Holiday_Key):\n",
    "    if Holiday_Key != 999:\n",
    "        return 'Holiday'\n",
    "    else:\n",
    "        return 'Non-Holiday'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conect to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pg.connect(host=\"appserver-01.alunos.di.fc.ul.pt\",database=\"ipai01\", user=\"ipai01\", password='ipai02')\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL System"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction from operational systems (Raw Tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = pd.read_excel('../Phase01/data/Raw_Tables/orders_RAW.xlsx')\n",
    "orders = pd.DataFrame(orders)\n",
    "customers_USA = pd.read_csv('../Phase01/data/Raw_Tables/customers_USA_RAW.csv', encoding='latin1')\n",
    "customers_USA = pd.DataFrame(customers_USA)\n",
    "returns = pd.read_csv('../Phase01/data/Raw_Tables/returns_RAW.csv', encoding='latin1')\n",
    "returns = pd.DataFrame(returns)\n",
    "sellers = pd.read_csv('../Phase01/data/Raw_Tables/sellers_RAW.csv', delimiter=';')\n",
    "sellers = pd.DataFrame(sellers)\n",
    "gdp = pd.read_csv(\"../Phase01/data/Raw_Tables/GDP_USA_RAW.csv\", delimiter=\",\", encoding=\"windows-1252\")\n",
    "gdp = pd.DataFrame(gdp)\n",
    "holiday = pd.read_csv(\"../Phase01/data/Raw_Tables/holiday_USA_RAW.csv\", delimiter=\",\", encoding=\"windows-1252\")\n",
    "holiday = pd.DataFrame(holiday)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation, Dim creation and Loading "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holiday Dimension"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afbso\\AppData\\Local\\Temp\\ipykernel_16456\\3134767474.py:16: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  holiday['Date'] = pd.to_datetime(holiday['Date'], infer_datetime_format = True)\n"
     ]
    }
   ],
   "source": [
    "# Add new Row for \"No Holiday\"\n",
    "new_row = pd.DataFrame({\n",
    "    \"Date\": ['2012-01-01'],\n",
    "    \"Holiday\": [\"No_Holiday\"],\n",
    "    \"WeekDay\": ['No_Holiday'],\n",
    "    \"Month\": [1],\n",
    "    \"Day\": [1],\n",
    "    \"Year\": [2012]\n",
    "})\n",
    "holiday = pd.concat([new_row, holiday], ignore_index=True)\n",
    "\n",
    "# Filter the years that are not between 2012 and 2015\n",
    "holiday = holiday[holiday['Year'].isin([2012, 2013, 2014, 2015])]\n",
    "\n",
    "# Convert the column Date to a date data type\n",
    "holiday['Date'] = pd.to_datetime(holiday['Date'], infer_datetime_format = True)\n",
    "#holiday['Date'] = holiday['Date'].dt.strftime('%d-%m-%Y')\n",
    "\n",
    "# Correct  \" New Yearâ€™s Eve \" & \" Valentineâ€™s Day \" \n",
    "holiday[\"Holiday\"] = holiday[\"Holiday\"].replace({\n",
    "    \"New Yearâ€™s Eve\": \"New Years Eve\",\n",
    "    \"Valentineâ€™s Day\": \"Valentines Day\"\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dim Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empty DataFrame\n",
    "Holiday_Dimension = pd.DataFrame()\n",
    "#Columns\n",
    "#Full Holiday Date\n",
    "Holiday_Dimension[\"Full_Holiday_Date\"] = holiday[\"Date\"]\n",
    "\n",
    "# Holiday Key (PK)\n",
    "Holiday_Dimension['Holiday_Key'] = range(1, len(Holiday_Dimension)+1)\n",
    "\n",
    "# Holiday Name\n",
    "Holiday_Dimension[\"Holiday_Name\"] = holiday[\"Holiday\"]\n",
    "\n",
    "# Year Holiday\n",
    "Holiday_Dimension[\"Year_Holiday\"] = holiday[\"Year\"]\n",
    "\n",
    "# Month Holiday\t\n",
    "Holiday_Dimension[\"Month_Holiday\"] = holiday[\"Month\"]\n",
    "\n",
    "# Day Month Holiday\n",
    "Holiday_Dimension[\"Day_Month_Holiday\"] = holiday[\"Day\"]\n",
    "\n",
    "# Day Week Holiday\n",
    "Holiday_Dimension['Day_Week_Holiday'] = Holiday_Dimension['Full_Holiday_Date'].dt.strftime('%A')\n",
    "\n",
    "# Change No Holiday Key\n",
    "Holiday_Dimension.at[0, 'Holiday_Key'] = 999"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Table in DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "DependentObjectsStillExist",
     "evalue": "cannot drop table holiday_dimension because other objects depend on it\nDETAIL:  constraint ship_date_dimension_holiday_key_fkey on table ship_date_dimension depends on table holiday_dimension\nHINT:  Use DROP ... CASCADE to drop the dependent objects too.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDependentObjectsStillExist\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ASobreira\\OneDrive - Universidade de Lisboa\\MCD\\2º Semestre\\I.P.A.I\\IPAI_project\\Phase03\\ETL.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ASobreira/OneDrive%20-%20Universidade%20de%20Lisboa/MCD/2%C2%BA%20Semestre/I.P.A.I/IPAI_project/Phase03/ETL.ipynb#Y111sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Create SQL Table in DB\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ASobreira/OneDrive%20-%20Universidade%20de%20Lisboa/MCD/2%C2%BA%20Semestre/I.P.A.I/IPAI_project/Phase03/ETL.ipynb#Y111sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m sql_Holiday_Dimension \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ASobreira/OneDrive%20-%20Universidade%20de%20Lisboa/MCD/2%C2%BA%20Semestre/I.P.A.I/IPAI_project/Phase03/ETL.ipynb#Y111sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ASobreira/OneDrive%20-%20Universidade%20de%20Lisboa/MCD/2%C2%BA%20Semestre/I.P.A.I/IPAI_project/Phase03/ETL.ipynb#Y111sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ASobreira/OneDrive%20-%20Universidade%20de%20Lisboa/MCD/2%C2%BA%20Semestre/I.P.A.I/IPAI_project/Phase03/ETL.ipynb#Y111sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m);\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ASobreira/OneDrive%20-%20Universidade%20de%20Lisboa/MCD/2%C2%BA%20Semestre/I.P.A.I/IPAI_project/Phase03/ETL.ipynb#Y111sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ASobreira/OneDrive%20-%20Universidade%20de%20Lisboa/MCD/2%C2%BA%20Semestre/I.P.A.I/IPAI_project/Phase03/ETL.ipynb#Y111sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m cursor\u001b[39m.\u001b[39;49mexecute(\u001b[39m\"\u001b[39;49m\u001b[39mDROP table IF EXISTS Holiday_Dimension;\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ASobreira/OneDrive%20-%20Universidade%20de%20Lisboa/MCD/2%C2%BA%20Semestre/I.P.A.I/IPAI_project/Phase03/ETL.ipynb#Y111sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m cursor\u001b[39m.\u001b[39mexecute(sql_Holiday_Dimension)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ASobreira/OneDrive%20-%20Universidade%20de%20Lisboa/MCD/2%C2%BA%20Semestre/I.P.A.I/IPAI_project/Phase03/ETL.ipynb#Y111sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m conn\u001b[39m.\u001b[39mcommit()\n",
      "\u001b[1;31mDependentObjectsStillExist\u001b[0m: cannot drop table holiday_dimension because other objects depend on it\nDETAIL:  constraint ship_date_dimension_holiday_key_fkey on table ship_date_dimension depends on table holiday_dimension\nHINT:  Use DROP ... CASCADE to drop the dependent objects too.\n"
     ]
    }
   ],
   "source": [
    "# Check transaction status and perform rollback if necessary\n",
    "if conn.status == pg.extensions.STATUS_IN_TRANSACTION:\n",
    "    conn.rollback()\n",
    "\n",
    "# Create SQL Table in DB\n",
    "sql_Holiday_Dimension = \"\"\"\n",
    "\n",
    "\n",
    "CREATE TABLE Holiday_Dimension (\n",
    "  Full_Holiday_Date TIMESTAMP NULL,\n",
    "  Holiday_Key  NUMERIC(9,0),\n",
    "  Holiday_Name VARCHAR(100) NOT NULL,\n",
    "  Year_Holiday NUMERIC(4,0) NOT NULL,\n",
    "  Month_Holiday NUMERIC(2,0) NOT NULL,\n",
    "  Day_Month_Holiday NUMERIC(2,0) NOT NULL,\n",
    "  Day_Week_Holiday VARCHAR(100) NOT NULL,\n",
    "  \n",
    "--\n",
    "  PRIMARY KEY (Holiday_Key),\n",
    "--\n",
    "  CHECK (Holiday_Key > 0)\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(\"DROP table IF EXISTS Holiday_Dimension;\")\n",
    "cursor.execute(sql_Holiday_Dimension)\n",
    "conn.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Data into Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into DB\n",
    "Holiday_Dimension_list = Holiday_Dimension.to_numpy().tolist()\n",
    "\n",
    "sql_holiday = \"INSERT INTO Holiday_Dimension(Full_Holiday_Date, Holiday_Key, Holiday_Name, Year_Holiday, Month_Holiday, Day_Month_Holiday, Day_Week_Holiday) VALUES(%s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "cursor.executemany(sql_holiday, Holiday_Dimension_list)\n",
    "conn.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GDP Dimension "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the GDP_USA dataset the following steps were performed:\n",
    "- Read in the dataset\n",
    "- Filter out all entries where the state is either Alaska or Hawaii\n",
    "- Remove Region, SUB-REGION, County columns\n",
    "- Filter the years that are not between 2012 and 2015\n",
    "- Convert Year to an integer date type\n",
    "- Calculate the mean and sum of the GDP values for each state and year"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out all entries where the state is either Alaska or Hawaii.\n",
    "gdp = gdp[(gdp['State'] != \"Alaska\") & (gdp['State'] != \"Hawaii\")]\n",
    "\n",
    "# Remove Region, SUB-REGION, County columns\n",
    "gdp = gdp.drop(['Region', 'SUB_REGION', 'County'], axis=1)\n",
    "\n",
    "# Filter the years that are not between 2012 and 2015\n",
    "gdp = gdp[gdp['Year'].isin([2012, 2013, 2014, 2015])]\n",
    "\n",
    "# Convert Year to an integer date type\n",
    "gdp['Year'] = pd.to_datetime(gdp['Year'], format='%Y')\n",
    "\n",
    "# Calculate the mean of the GDP values for each state and year\n",
    "result = gdp.groupby(['State', 'Year'])['GDP (Chained $)'].mean().reset_index()\n",
    "\n",
    "# Remove duplicate states\n",
    "result = result.drop_duplicates(subset=['State'])\n",
    "\n",
    "# Add a new column 'State Key' as a unique identifier for each state\n",
    "result['State_Key_GDP'] = range(1, len(result) + 1)\n",
    "\n",
    "# Pivot the data to get average GDP for each year\n",
    "gdp_pivot = pd.pivot_table(gdp, values='GDP (Chained $)', index='State', columns='Year').reset_index()\n",
    "\n",
    "# Rename the columns with year-specific average GDP\n",
    "gdp_pivot.rename(columns={pd.to_datetime('2012'): 'Average_GDP_2012_billions',\n",
    "                          pd.to_datetime('2013'): 'Average_GDP_2013_billions',\n",
    "                          pd.to_datetime('2014'): 'Average_GDP_2014_billions',\n",
    "                          pd.to_datetime('2015'): 'Average_GDP_2015_billions'}, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dim Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the result with the pivot table\n",
    "GDP_Dimension = pd.merge(result[['State', 'State_Key_GDP']], gdp_pivot, on='State')\n",
    "\n",
    "# Reorder the columns with 'State Key' as the first column\n",
    "GDP_Dimension = GDP_Dimension[['State_Key_GDP', 'State', 'Average_GDP_2012_billions', 'Average_GDP_2013_billions', 'Average_GDP_2014_billions', 'Average_GDP_2015_billions']]\n",
    "\n",
    "GDP_Dimension[['Average_GDP_2012_billions', 'Average_GDP_2013_billions', 'Average_GDP_2014_billions', 'Average_GDP_2015_billions']] = GDP_Dimension[['Average_GDP_2012_billions', 'Average_GDP_2013_billions', 'Average_GDP_2014_billions', 'Average_GDP_2015_billions']].div(1000000000).round(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Table in DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check transaction status and perform rollback if necessary\n",
    "if conn.status == pg.extensions.STATUS_IN_TRANSACTION:\n",
    "    conn.rollback()\n",
    "\n",
    "# Create SQL Table in DB\n",
    "sql_GDP_Dimension = \"\"\"\n",
    "\n",
    "CREATE TABLE GDP_Dimension (\n",
    "  State_Key_GDP NUMERIC(9,0),\n",
    "  State VARCHAR(100) NOT NULL,\n",
    "  Average_GDP_2012_billions FLOAT(2) NOT NULL,\n",
    "  Average_GDP_2013_billions FLOAT(2) NOT NULL,\n",
    "  Average_GDP_2014_billions FLOAT(2) NOT NULL,\n",
    "  Average_GDP_2015_billions FLOAT(2) NOT NULL,\n",
    "  \n",
    "--\n",
    "  PRIMARY KEY (State_Key_GDP),\n",
    "--\n",
    "  CHECK (State_Key_GDP > 0)\n",
    ");\n",
    "\"\"\"\n",
    "# Drop the GDP_Dimension table and its dependent objects\n",
    "cursor.execute(\"DROP TABLE IF EXISTS Customer_Dimension CASCADE;\")\n",
    "cursor.execute(\"DROP TABLE IF EXISTS GDP_Dimension CASCADE;\")\n",
    "\n",
    "conn.commit()\n",
    "cursor.execute(sql_GDP_Dimension)\n",
    "conn.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Data into Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP_Dimension_list = GDP_Dimension.to_numpy().tolist()\n",
    "\n",
    "sql_GDP = \"INSERT INTO GDP_Dimension(State_Key_GDP, State, Average_GDP_2012_billions, Average_GDP_2013_billions, Average_GDP_2014_billions, Average_GDP_2015_billions) VALUES(%s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "cursor.executemany(sql_GDP, GDP_Dimension_list)\n",
    "conn.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shipment Date Dimension"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Row ID and Quantity to integer data type\n",
    "orders['Row ID'] = orders['Row ID'].astype(int)\n",
    "orders['Quantity'] = orders['Quantity'].astype(int)\n",
    "\n",
    "# Convert Order ID, Customer ID, Customer Name, City, State, Country, Region, Market, Product ID and Product Name to string data type\n",
    "orders['Order ID'] = orders['Order ID'].astype(str)\n",
    "orders['Customer ID'] = orders['Customer ID'].astype(str)\n",
    "orders['Customer Name'] = orders['Customer Name'].astype(str)\n",
    "orders['City'] = orders['City'].astype(str)\n",
    "orders['State'] = orders['State'].astype(str)\n",
    "orders['Country'] = orders['Country'].astype(str)\n",
    "orders['Region'] = orders['Region'].astype(str)\n",
    "orders['Market'] = orders['Market'].astype(str)\n",
    "orders['Product ID'] = orders['Product ID'].astype(str)\n",
    "orders['Product Name'] = orders['Product Name'].astype(str)\n",
    "\n",
    "# Convert Ship Date and Order Date to date data type\n",
    "orders['Ship Date'] = pd.to_datetime(orders['Ship Date'])\n",
    "orders['Order Date'] = pd.to_datetime(orders['Order Date'])\n",
    "\n",
    "# Convert Segment, Category, Sub-Category and Order Priority to category data type\n",
    "orders['Segment'] = orders['Segment'].astype('category')\n",
    "orders['Category'] = orders['Category'].astype('category')\n",
    "orders['Sub-Category'] = orders['Sub-Category'].astype('category')\n",
    "orders['Order Priority'] = orders['Order Priority'].astype('category')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dim Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empty DataFrame\n",
    "Ship_Date_Dimension = pd.DataFrame()\n",
    "\n",
    "# Columns\n",
    "# Ship_Full_Date_Description\n",
    "Ship_Date_Dimension[\"Ship_Full_Date_Description\"] = orders[\"Ship Date\"].unique()\n",
    "\n",
    "# Ship Year\n",
    "Ship_Date_Dimension['Ship_Year'] = Ship_Date_Dimension['Ship_Full_Date_Description'].dt.year\n",
    "\n",
    "# Ship Season   \n",
    "Ship_Date_Dimension['Ship_Season'] = Ship_Date_Dimension['Ship_Full_Date_Description'].apply(get_season)\n",
    "    \n",
    "# Ship Semester    \n",
    "Ship_Date_Dimension['Ship_Semester'] = Ship_Date_Dimension['Ship_Full_Date_Description'].apply(get_semester)\n",
    "\n",
    "# Ship Month Number Year\n",
    "Ship_Date_Dimension['Ship_Month_Number_Year '] = Ship_Date_Dimension['Ship_Full_Date_Description'].dt.month\n",
    "\n",
    "# Ship Week Number Year\n",
    "Ship_Date_Dimension['Ship_Week_Number_Year'] = Ship_Date_Dimension['Ship_Full_Date_Description'].dt.isocalendar().week\n",
    "\n",
    "# Ship Day Number Month\n",
    "Ship_Date_Dimension['Ship_Day_Number_Month'] = Ship_Date_Dimension['Ship_Full_Date_Description'].dt.days_in_month\n",
    "\n",
    "# Ship Day  Number Week\n",
    "Ship_Date_Dimension['Ship_Day_Number_Week'] = Ship_Date_Dimension['Ship_Full_Date_Description'].dt.day_of_week\n",
    "\n",
    "# Ship Day Name Week\n",
    "Ship_Date_Dimension['Ship_Day_Name_Week'] = Ship_Date_Dimension['Ship_Full_Date_Description'].dt.strftime('%A')\n",
    "\n",
    "# Weekend Indicator   \n",
    "Ship_Date_Dimension['Weekend_Indicator'] = Ship_Date_Dimension['Ship_Full_Date_Description'].dt.dayofweek.apply(get_weekend_indicator)\n",
    "\n",
    "# Holiday Key\n",
    "Holiday_Dimension_selected = Holiday_Dimension[[\"Full_Holiday_Date\",'Holiday_Key']]\n",
    "\n",
    "Ship_Date_Dimension = pd.merge(Ship_Date_Dimension, Holiday_Dimension_selected, left_on='Ship_Full_Date_Description', right_on='Full_Holiday_Date', how='left')\n",
    "\n",
    "Ship_Date_Dimension.drop(\"Full_Holiday_Date\", axis=1, inplace=True)\n",
    "#Ship_Date_Dimension['Holiday_Key'].fillna('No Key', inplace=True)\n",
    "\n",
    "Ship_Date_Dimension[\"Holiday_Key\"] = Ship_Date_Dimension[\"Holiday_Key\"].fillna(999)\n",
    "\n",
    "# Holiday indicator   \n",
    "Ship_Date_Dimension['Holiday_Indicator'] = Ship_Date_Dimension['Holiday_Key'].apply(get_holiday_indicator)\n",
    "\n",
    "# Ship Date Key\n",
    "Ship_Date_Dimension['Ship_Date_Key'] = range(1, len(Ship_Date_Dimension[\"Ship_Full_Date_Description\"])+1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Table in DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check transaction status and perform rollback if necessary\n",
    "if conn.status == pg.extensions.STATUS_IN_TRANSACTION:\n",
    "    conn.rollback()\n",
    "    \n",
    "# Create SQL Table in DB\n",
    "sql_Ship_Date_Dimension = \"\"\"\n",
    "\n",
    "CREATE TABLE Ship_Date_Dimension (\n",
    "  Ship_Full_Date_Description TIMESTAMP NOT NULL,\n",
    "  Ship_Year NUMERIC(4,0) NOT NULL,\n",
    "  Ship_Season VARCHAR(100) NOT NULL,\n",
    "  Ship_Semester NUMERIC(4,0) NOT NULL,\n",
    "  Ship_Month_Number_Year NUMERIC(2,0) NOT NULL,\n",
    "  Ship_Week_Number_Year NUMERIC(4,0) NOT NULL,\n",
    "  Ship_Day_Number_Month NUMERIC(2,0) NOT NULL,\n",
    "  Ship_Day_Number_Week NUMERIC(1,0) NOT NULL,\n",
    "  Ship_Day_Name_Week VARCHAR(100) NOT NULL,\n",
    "  Weekend_Indicator VARCHAR(100) NOT NULL,\n",
    "  Holiday_Key NUMERIC(3,0) NOT NULL,  \n",
    "  Holiday_Indicator VARCHAR(100) NOT NULL,\n",
    "  Ship_Date_Key  NUMERIC(9,0),\n",
    "  \n",
    " --\n",
    "  PRIMARY KEY (Ship_Date_Key),\n",
    "  FOREIGN KEY (Holiday_Key) REFERENCES Holiday_Dimension(Holiday_Key),\n",
    "--\n",
    "  CHECK (Ship_Date_Key > 0)\n",
    ");\n",
    "  \n",
    "\"\"\"\n",
    "cursor.execute(\"DROP table IF EXISTS Ship_Date_Dimension;\")\n",
    "cursor.execute(sql_Ship_Date_Dimension)\n",
    "conn.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Data into Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into DB\n",
    "Ship_Date_Dimension_list = Ship_Date_Dimension.to_numpy().tolist()\n",
    "\n",
    "sql_Ship_Date = \"INSERT INTO Ship_Date_Dimension(Ship_Full_Date_Description, Ship_Year, Ship_Season, Ship_Semester, Ship_Month_Number_Year, Ship_Week_Number_Year, Ship_Day_Number_Month, Ship_Day_Number_Week, Ship_Day_Name_Week, Weekend_Indicator, Holiday_Key, Holiday_Indicator, Ship_Date_Key) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "cursor.executemany(sql_Ship_Date, Ship_Date_Dimension_list)\n",
    "conn.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order Date Dimension "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performed for  Orders "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dim Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empty DataFrame\n",
    "Order_Date_Dimension = pd.DataFrame()\n",
    "\n",
    "# Columns\n",
    "# Order_Full_Date_Description\n",
    "Order_Date_Dimension[\"Order_Full_Date_Description\"] = orders[\"Order Date\"].unique()\n",
    "\n",
    "# Order Year\n",
    "Order_Date_Dimension['Order_Year'] = Order_Date_Dimension['Order_Full_Date_Description'].dt.year\n",
    "\n",
    "# Order Season    \n",
    "Order_Date_Dimension['Order_Season'] = Order_Date_Dimension['Order_Full_Date_Description'].apply(get_season)\n",
    "    \n",
    "# Order Semester   \n",
    "Order_Date_Dimension['Order_Semester'] = Order_Date_Dimension['Order_Full_Date_Description'].apply(get_semester)\n",
    "\n",
    "# Order Month Number Year\n",
    "Order_Date_Dimension['Order_Month_Number_Year'] = Order_Date_Dimension['Order_Full_Date_Description'].dt.month\n",
    "\n",
    "# Order Week Number Year\n",
    "Order_Date_Dimension['Order_Week_Number_Year'] = Order_Date_Dimension['Order_Full_Date_Description'].dt.isocalendar().week\n",
    "\n",
    "# Order Day Number Month\n",
    "Order_Date_Dimension['Order_Day_Number_Month'] = Order_Date_Dimension['Order_Full_Date_Description'].dt.days_in_month\n",
    "\n",
    "# Order Day  Number Week\n",
    "Order_Date_Dimension['Order_Day_Number_Week'] = Order_Date_Dimension['Order_Full_Date_Description'].dt.day_of_week\n",
    "\n",
    "# Order Day Name Week\n",
    "Order_Date_Dimension['Order_Day_Name_Week'] = Order_Date_Dimension['Order_Full_Date_Description'].dt.strftime('%A')\n",
    "\n",
    "# Weekend Indicator\n",
    "    \n",
    "Order_Date_Dimension['Weekend_Indicator'] = Order_Date_Dimension['Order_Full_Date_Description'].dt.dayofweek.apply(get_weekend_indicator)\n",
    "# Holiday Key\n",
    "Holiday_Dimension_selected = Holiday_Dimension[[\"Full_Holiday_Date\",'Holiday_Key']]\n",
    "Order_Date_Dimension = pd.merge(Order_Date_Dimension, Holiday_Dimension_selected, left_on='Order_Full_Date_Description', right_on='Full_Holiday_Date', how='left')\n",
    "Order_Date_Dimension.drop(\"Full_Holiday_Date\", axis=1, inplace=True)\n",
    "#Order_Date_Dimension['Holiday_Key'].fillna('No Key', inplace=True)\n",
    "Order_Date_Dimension[\"Holiday_Key\"] = Order_Date_Dimension[\"Holiday_Key\"].fillna(999)\n",
    "# Holiday indicator\n",
    "Order_Date_Dimension['Holiday_Indicator'] = Order_Date_Dimension['Holiday_Key'].apply(get_holiday_indicator)\n",
    "# Order Date Key\n",
    "Order_Date_Dimension['Order_Date_Key'] = range(1, len(Order_Date_Dimension[\"Order_Full_Date_Description\"])+1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Table in DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check transaction status and perform rollback if necessary\n",
    "if conn.status == pg.extensions.STATUS_IN_TRANSACTION:\n",
    "    conn.rollback()\n",
    "\n",
    "# Create SQL Table in DB\n",
    "sql_Order_Date_Dimension = \"\"\"\n",
    "\n",
    "CREATE TABLE Order_Date_Dimension (\n",
    "  Order_Full_Date_Description TIMESTAMP NOT NULL,\n",
    "  Order_Year NUMERIC(4,0) NOT NULL,\n",
    "  Order_Season VARCHAR(100) NOT NULL,\n",
    "  Order_Semester NUMERIC(4,0) NOT NULL,\n",
    "  Order_Month_Number_Year NUMERIC(2,0) NOT NULL,\n",
    "  Order_Week_Number_Year NUMERIC(4,0) NOT NULL,\n",
    "  Order_Day_Number_Month NUMERIC(2,0) NOT NULL,\n",
    "  Order_Day_Number_Week NUMERIC(1,0) NOT NULL,\n",
    "  Order_Day_Name_Week VARCHAR(100) NOT NULL,\n",
    "  Weekend_Indicator VARCHAR(100) NOT NULL,\n",
    "  Holiday_Key NUMERIC(3,0) NOT NULL,  \n",
    "  Holiday_Indicator VARCHAR(100) NOT NULL,\n",
    "  Order_Date_Key  NUMERIC(9,0),\n",
    "  \n",
    " --\n",
    "  PRIMARY KEY (Order_Date_Key),\n",
    "  FOREIGN KEY (Holiday_Key) REFERENCES Holiday_Dimension(Holiday_Key),\n",
    "--\n",
    "  CHECK (Order_Date_Key > 0)\n",
    ");\n",
    "  \n",
    "\"\"\"\n",
    "cursor.execute(\"DROP table IF EXISTS Order_Date_Dimension;\")\n",
    "cursor.execute(sql_Order_Date_Dimension)\n",
    "conn.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Data into Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into DB\n",
    "Order_Date_Dimension_list = Order_Date_Dimension.to_numpy().tolist()\n",
    "\n",
    "sql_Order_Date = \"INSERT INTO Order_Date_Dimension(Order_Full_Date_Description, Order_Year, Order_Season, Order_Semester, Order_Month_Number_Year, Order_Week_Number_Year, Order_Day_Number_Month, Order_Day_Number_Week, Order_Day_Name_Week, Weekend_Indicator, Holiday_Key, Holiday_Indicator, Order_Date_Key) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "cursor.executemany(sql_Order_Date, Order_Date_Dimension_list)\n",
    "conn.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Dimension"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performed for  Orders "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dim Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empty DataFrame\n",
    "Product_Dimension = pd.DataFrame()\n",
    "\n",
    "# Product ID\n",
    "Product_Dimension[\"Product_ID\"] = orders[\"Product ID\"]\n",
    "\n",
    "# Product Name\n",
    "Product_Dimension[\"Product_Name\"] = orders[\"Product Name\"]\n",
    "\n",
    "# Category\n",
    "Product_Dimension[\"Category\"] = orders[\"Category\"]\n",
    "\n",
    "# Sub Category\n",
    "Product_Dimension[\"Sub_Category\"] = orders[\"Sub-Category\"]\n",
    "\n",
    "# Drop Duplicates\n",
    "Product_Dimension.drop_duplicates(inplace=True)\n",
    "\n",
    "# Product Key\n",
    "Product_Dimension['Product_Key'] = range(1, len(Product_Dimension)+1)\n",
    "\n",
    "# Re establish Correct Order\n",
    "Product_Dimension = Product_Dimension[[\"Product_ID\", \"Product_Key\", \"Product_Name\", \"Category\", \"Sub_Category\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Table in DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        OFF-ST-4258\n",
       "1        TEC-MA-4190\n",
       "2        FUR-BO-3647\n",
       "3        OFF-FA-2945\n",
       "4        OFF-ST-6249\n",
       "            ...     \n",
       "49209    TEC-PH-5659\n",
       "49298    OFF-PA-6599\n",
       "49975    OFF-AP-4215\n",
       "50138    TEC-MA-3855\n",
       "50571    OFF-LA-3220\n",
       "Name: Product_ID, Length: 3788, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Product_Dimension[\"Product_ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check transaction status and perform rollback if necessary\n",
    "if conn.status == pg.extensions.STATUS_IN_TRANSACTION:\n",
    "    conn.rollback()\n",
    "\n",
    "# Create SQL Table in DB\n",
    "sql_Product_Dimension = \"\"\"\n",
    "\n",
    "\n",
    "CREATE TABLE Product_Dimension (\n",
    "  Product_ID VARCHAR(500) NOT NULL,\n",
    "  Product_Key  NUMERIC(9,0),\n",
    "  Product_Name VARCHAR(500) NOT NULL,\n",
    "  Category VARCHAR(500) NOT NULL,\n",
    "  Sub_Category VARCHAR(500) NOT NULL,\n",
    "  \n",
    "--\n",
    "  PRIMARY KEY (Product_Key),\n",
    "--\n",
    "  CHECK (Product_Key > 0)\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(\"DROP table IF EXISTS Product_Dimension;\")\n",
    "cursor.execute(sql_Product_Dimension)\n",
    "conn.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Data into Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into DB\n",
    "Product_Dimension_list = Product_Dimension.to_numpy().tolist()\n",
    "\n",
    "sql_Ship_Date = \"INSERT INTO Product_Dimension(Product_ID, Product_Key, Product_Name, Category, Sub_Category) VALUES (%s, %s, %s, %s, %s)\"\n",
    "\n",
    "cursor.executemany(sql_Ship_Date, Product_Dimension_list)\n",
    "conn.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order Information Dimension"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data files needed\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "order_info = pd.read_excel('orders_RAW.xlsx')\n",
    "order_info = pd.DataFrame(order_info)\n",
    "\n",
    "returns_aux = pd.read_csv('returns_RAW.csv', encoding='latin1')\n",
    "returns_aux = pd.DataFrame(returns_aux)\n",
    "\n",
    "# Dropping unrelated columns and rows with entirely duplicate records\n",
    "\n",
    "order_info = orders.drop(['Row ID', 'Order Date', 'Ship Date', 'Customer ID', 'Customer Name', 'Segment', 'Postal Code', 'City', 'State', 'Country', 'Region', 'Market', 'Product ID', 'Category', 'Sub-Category', 'Product Name', 'Sales', 'Quantity', 'Discount', 'Profit', 'Shipping Cost'], axis=1)\n",
    "returns_aux = returns.drop(['Region'], axis=1)\n",
    "\n",
    "# Checking if data types used are correct\n",
    "\n",
    "order_info['Order ID'] = order_info['Order ID'].astype(str)\n",
    "order_info['Ship Mode'] = order_info['Ship Mode'].astype(str)\n",
    "order_info['Order Priority'] = order_info['Order Priority'].astype(str)\n",
    "\n",
    "# Filter orders that are repeated (same Order ID)\n",
    "\n",
    "order_info = order_info.drop_duplicates(subset='Order ID')\n",
    "\n",
    "#maneira alterada\n",
    "\n",
    "order_info_df = pd.merge(order_info, returns_aux, on=['Order ID'], how=\"left\")\n",
    "\n",
    "order_info_df.rename(columns = {'Returned':'Returned Indicator'}, inplace = True)\n",
    "\n",
    "order_info_df[\"Returned Indicator\"] = order_info_df[\"Returned Indicator\"].map({\"Yes\": \"Returned\"})\n",
    "\n",
    "order_info_df[\"Returned Indicator\"].replace(np.nan, \"Not Returned\", inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dim Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding PK and reordering columns\n",
    "\n",
    "Order_Information_Dimension = order_info_df[['Order ID', 'Ship Mode', 'Order Priority', 'Returned Indicator']]\n",
    "\n",
    "Order_Information_Dimension[\"Order Key\"] = pd.factorize(order_info['Order ID'])[0] + 1\n",
    "\n",
    "Order_Information_Dimension = Order_Information_Dimension.reindex(columns=['Order Key', 'Order ID', 'Returned Indicator', 'Ship Mode', 'Order Priority']).copy()\n",
    "\n",
    "Order_Information_Dimension"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Table in DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating table\n",
    "\n",
    "if conn.status == pg.extensions.STATUS_IN_TRANSACTION:\n",
    "    conn.rollback()\n",
    "\n",
    "sql_Order_Information_Dimension = \"\"\"\n",
    "\n",
    "CREATE TABLE Order_Information_Dimension (\n",
    "  Order_Key  NUMERIC(9,0),\n",
    "  Order_ID VARCHAR(100) NOT NULL,\n",
    "  Returned_Indicator VARCHAR(100) NOT NULL,\n",
    "  Ship_Mode VARCHAR(100) NOT NULL,\n",
    "  Order_Priority VARCHAR(100) NOT NULL,\n",
    "  \n",
    "--\n",
    "  PRIMARY KEY (Order_Key),\n",
    "--\n",
    "  CHECK (Order_Key > 0)\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(\"DROP table IF EXISTS Order_Information_Dimension;\")\n",
    "cursor.execute(sql_Order_Information_Dimension)\n",
    "conn.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Data into Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserting values\n",
    "\n",
    "Order_Information_Dimension_list = Order_Information_Dimension.to_numpy().tolist()\n",
    "\n",
    "sql_Order_Information = \"INSERT INTO Order_Information_Dimension(Order_Key, Order_ID, Returned_Indicator, Ship_Mode, Order_Priority) VALUES(%s, %s, %s, %s, %s)\"\n",
    "\n",
    "cursor.executemany(sql_Order_Information, Order_Information_Dimension_list)\n",
    "conn.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seller Dimension"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performed for  Orders # Reading data files needed\n",
    "\n",
    "sellers = pd.read_csv('sellers_RAW.csv', delimiter=';')\n",
    "sellers = pd.DataFrame(sellers)\n",
    "\n",
    "order_info_aux = pd.read_excel('orders_RAW.xlsx')\n",
    "order_info_aux = pd.DataFrame(order_info_aux)\n",
    "\n",
    "# Dropping unrelated columns and rows with entirely duplicate records\n",
    "\n",
    "order_info_aux.drop(['Row ID', 'Order ID', 'Order Date', 'Ship Date', 'Customer ID', 'Customer Name', 'Segment', 'Postal Code', 'Product ID', 'Category', 'Sub-Category', 'Product Name', 'Sales', 'Quantity', 'Discount', 'Profit', 'Shipping Cost', 'Ship Mode', 'Order Priority'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if data types used are correct\n",
    "\n",
    "order_info_aux['City'] = order_info_aux['City'].astype(str)\n",
    "order_info_aux['State'] = order_info_aux['State'].astype(str)\n",
    "order_info_aux['Country'] = order_info_aux['Country'].astype(str)\n",
    "order_info_aux['Region'] = order_info_aux['Region'].astype(str)\n",
    "order_info_aux['Market'] = order_info_aux['Market'].astype(str)\n",
    "order_info_aux['Market'] = order_info_aux['Market'].astype(str)\n",
    "sellers['Person'] = sellers['Person'].astype(str)\n",
    "sellers['Region'] = sellers['Region'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_info_aux = order_info_aux.drop_duplicates(subset='City')#se nao der certo secalhar tirar o keep='first'\n",
    "\n",
    "# Filter orders that have repeated City and State together\n",
    "#since there may be Cities in different locations with the same name but no repeated combinations of City and State together\n",
    "\n",
    "order_info_aux = order_info_aux.drop_duplicates(subset=['City', 'State'], keep='first')#se nao der certo secalhar tirar o keep='first'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing quotation marks and double quotation marks from any values\n",
    "\n",
    "order_info_aux['City'] = order_info_aux['City'].str.replace('[\\'\\\"]', '')\n",
    "order_info_aux['State'] = order_info_aux['State'].str.replace('[\\'\\\"]', '')\n",
    "order_info_aux['Country'] = order_info_aux['Country'].str.replace('[\\'\\\"]', '')\n",
    "order_info_aux['Region'] = order_info_aux['Region'].str.replace('[\\'\\\"]', '')\n",
    "order_info_aux['Market'] = order_info_aux['Market'].str.replace('[\\'\\\"]', '')\n",
    "sellers[\"Person\"] = sellers[\"Person\"].str.replace('[\\'\\\"]', '')\n",
    "sellers[\"Region\"] = sellers[\"Region\"].str.replace('[\\'\\\"]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining dataframes on Region Column\n",
    "\n",
    "seller_df = pd.merge(order_info_aux, sellers, how = \"left\",left_on=['Region'], right_on=['Region']).fillna(\"Canada\") # Eartern and Western Canada do not exist on the orders table hence the value Canada is used as default value.\n",
    "\n",
    "\n",
    "seller_df.rename(columns = {'Person':'Seller Name'}, inplace = True)\n",
    "seller_df.rename(columns = {'Market':'Seller Market'}, inplace = True)\n",
    "seller_df.rename(columns = {'Region':'Seller Region'}, inplace = True)\n",
    "seller_df.rename(columns = {'Country':'Seller Country'}, inplace = True)\n",
    "seller_df.rename(columns = {'State':'Seller State'}, inplace = True)\n",
    "seller_df.rename(columns = {'City':'Seller City'}, inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dim Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding PK and reordering columns\n",
    "\n",
    "Seller_Dimension = seller_df[['Seller City', 'Seller State', 'Seller Country', 'Seller Region', 'Seller Market', 'Seller Name']]\n",
    "\n",
    "Seller_Dimension[\"Seller Key\"] = pd.factorize(seller_df['Seller City'])[0] + 1\n",
    "\n",
    "Seller_Dimension = Seller_Dimension.reindex(columns=['Seller Key', 'Seller Name', 'Seller Market', 'Seller Region', 'Seller Country', 'Seller State', 'Seller City']).copy()\n",
    "\n",
    "Seller_Dimension"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Table in DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating table\n",
    "\n",
    "if conn.status == pg.extensions.STATUS_IN_TRANSACTION:\n",
    "    conn.rollback()\n",
    "\n",
    "sql_Seller_Dimension = \"\"\"\n",
    "\n",
    "CREATE TABLE Seller_Dimension (\n",
    "  Seller_Key  NUMERIC(9,0),\n",
    "  Seller_Name VARCHAR(100) NOT NULL,\n",
    "  Seller_Market VARCHAR(100) NOT NULL,\n",
    "  Seller_Region VARCHAR(100) NOT NULL,\n",
    "  Seller_Country VARCHAR(100) NOT NULL,\n",
    "  Seller_State VARCHAR(100) NOT NULL,\n",
    "  Seller_City VARCHAR(100) NOT NULL,\n",
    "  \n",
    "--\n",
    "  PRIMARY KEY (Seller_Key),\n",
    "--\n",
    "  CHECK (Seller_Key > 0)\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(\"DROP table IF EXISTS Seller_Dimension;\")\n",
    "cursor.execute(sql_Seller_Dimension)\n",
    "cursor.execute(\"TRUNCATE TABLE Seller_Dimension;\")\n",
    "conn.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Data into Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserting values\n",
    "\n",
    "Seller_Dimension_list = Seller_Dimension.to_numpy().tolist()\n",
    "\n",
    "sql_Seller_Dimension = \"INSERT INTO Seller_Dimension(Seller_Key, Seller_Name, Seller_Market, Seller_Region, Seller_Country, Seller_State, Seller_City) VALUES(%s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "cursor.executemany(sql_Seller_Dimension, Seller_Dimension_list)\n",
    "conn.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer Dimension- Jimmy 🥕"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Row ID and Quantity to integer data type\n",
    "customers_USA['Row ID'] = customers_USA['Row ID'].astype(int)\n",
    "customers_USA['Quantity'] = customers_USA['Quantity'].astype(int)\n",
    "\n",
    "# Convert Order ID, Customer ID, Customer Name, City, State, Country, Region, Market, Product ID and Product Name to string data type\n",
    "customers_USA['Order ID'] = customers_USA['Order ID'].astype(str)\n",
    "customers_USA['Customer ID'] = customers_USA['Customer ID'].astype(str)\n",
    "customers_USA['Customer Name'] = customers_USA['Customer Name'].astype(str)\n",
    "customers_USA['City'] = customers_USA['City'].astype(str)\n",
    "customers_USA['State'] = customers_USA['State'].astype(str)\n",
    "customers_USA['Country'] = customers_USA['Country'].astype(str)\n",
    "customers_USA['Region'] = customers_USA['Region'].astype(str)\n",
    "customers_USA['Product ID'] = customers_USA['Product ID'].astype(str)\n",
    "customers_USA['Product Name'] = customers_USA['Product Name'].astype(str)\n",
    "\n",
    "# Convert Ship Date and Order Date to date data type\n",
    "customers_USA['Ship Date'] = pd.to_datetime(customers_USA['Ship Date'])\n",
    "customers_USA['Order Date'] = pd.to_datetime(customers_USA['Order Date'])\n",
    "\n",
    "# Convert Segment, Category, Sub-Category and Order Priority to category data type\n",
    "customers_USA['Segment'] = customers_USA['Segment'].astype('category')\n",
    "customers_USA['Category'] = customers_USA['Category'].astype('category')\n",
    "customers_USA['Sub-Category'] = customers_USA['Sub-Category'].astype('category')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dim Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Customer Dimension DataFrame\n",
    "Customer_Dimension = customers_USA[['Customer ID', 'Customer Name', 'Segment', 'State', 'Region', 'City', 'Postal Code']]\n",
    "\n",
    "# Generate unique numerical identifiers for each customer\n",
    "Customer_Dimension['Customer Key'] = pd.factorize(Customer_Dimension['Customer ID'] + '_' + Customer_Dimension['City'])[0] + 1\n",
    "\n",
    "# Reorder the columns with 'Customer Key' as the first column\n",
    "Customer_Dimension = Customer_Dimension.reindex(columns=['Customer Key', 'Customer ID', 'Customer Name', 'Segment', 'State', 'Region', 'City', 'Postal Code']).copy()\n",
    "\n",
    "# Check if 'State Key Customer' column already exists\n",
    "if 'State_Key_Customer' not in Customer_Dimension.columns:\n",
    "    # Merge GDP_dimension and customer_dimension on 'State' column\n",
    "    Customer_Dimension = Customer_Dimension.merge(GDP_Dimension[['State', 'State_Key_GDP']], left_on='State', right_on='State', how='left')\n",
    "    # Add a unique constraint to the State_Key column in Customer_Dimension\n",
    "\n",
    "Customer_Dimension.rename(columns=lambda x: x.replace(' ', '_'), inplace=True)\n",
    "\n",
    "Customer_Dimension.rename(columns={'State_Key_GDP': 'State_Key_Customer'}, inplace=True)\n",
    "\n",
    "Customer_Dimension = Customer_Dimension.drop_duplicates(subset=['Customer_Key'])\n",
    "\n",
    "# Remove rows with specific customer names\n",
    "values_to_drop = ['Tom Zandusky', 'Cari MacIntyre', 'Kai Rey']\n",
    "Customer_Dimension = Customer_Dimension[~Customer_Dimension['Customer_Name'].isin(values_to_drop)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Table in DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check transaction status and perform rollback if necessary\n",
    "if conn.status == pg.extensions.STATUS_IN_TRANSACTION:\n",
    "    conn.rollback()\n",
    "\n",
    "# Create SQL Table in DB\n",
    "sql_Customer_Dimension = \"\"\"\n",
    "\n",
    "CREATE TABLE Customer_Dimension (\n",
    "  Customer_Key NUMERIC(9,0),\n",
    "  Customer_ID VARCHAR(100) NOT NULL,\n",
    "  Customer_Name VARCHAR(100) NOT NULL,\n",
    "  Segment VARCHAR(100) NOT NULL,\n",
    "  State VARCHAR(100) NOT NULL,\n",
    "  Region VARCHAR(100) NOT NULL,\n",
    "  City VARCHAR(100) NOT NULL,\n",
    "  Postal_Code VARCHAR(100) NOT NULL,\n",
    "  State_Key_Customer NUMERIC(9,0) NOT NULL,\n",
    "  \n",
    "--\n",
    "  PRIMARY KEY (Customer_Key),\n",
    "  FOREIGN KEY (State_Key_Customer) REFERENCES GDP_Dimension(State_Key_GDP),\n",
    "\n",
    "--\n",
    "  CHECK (Customer_Key > 0)\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(\"DROP table IF EXISTS Customer_Dimension;\")\n",
    "cursor.execute(sql_Customer_Dimension)\n",
    "conn.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Data into Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into DB\n",
    "Customer_Dimension_list = Customer_Dimension.to_numpy().tolist()\n",
    "\n",
    "sql_Customer = \"INSERT INTO Customer_Dimension(Customer_Key, Customer_ID, Customer_Name, Segment, State, Region, City, Postal_Code, State_Key_Customer) VALUES(%s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "cursor.executemany(sql_Customer, Customer_Dimension_list)\n",
    "conn.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facts Table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dim Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the orders data from Excel file\n",
    "orders = pd.read_excel('orders_RAW.xlsx')\n",
    "\n",
    "# Remove unnecessary quotes from the City column\n",
    "orders['City'] = orders['City'].str.replace('[\\'\\\"]', '')\n",
    "\n",
    "# Merge orders and product dimension based on Product ID\n",
    "facts = pd.merge(orders, Product_Dimension[['Product_ID', 'Product_Key']], left_on='Product ID', right_on='Product_ID', how='left')\n",
    "\n",
    "# Drop redundant columns\n",
    "facts.drop(['Product ID', 'Product Name', 'Category', 'Sub-Category', 'Product_ID', 'Discount', 'Postal Code'], axis=1, inplace=True)\n",
    "\n",
    "# Map Ship Date to Ship Date Key\n",
    "ship_date_mapping = Ship_Date_Dimension.set_index('Ship_Full_Date_Description')['Ship_Date_Key'].to_dict()\n",
    "facts['Ship_Date_Key'] = facts['Ship Date'].map(ship_date_mapping)\n",
    "\n",
    "# Map Order Date to Order Date Key\n",
    "order_date_mapping = Order_Date_Dimension.set_index('Order_Full_Date_Description')['Order_Date_Key'].to_dict()\n",
    "facts['Order_Date_Key'] = facts['Order Date'].map(order_date_mapping)\n",
    "\n",
    "\n",
    "# Merge with Seller Dimension based on City and Seller City columns\n",
    "facts = facts.merge(Seller_Dimension, left_on='City', right_on='Seller City', how='left')\n",
    "\n",
    "# Drop unnecessary columns from Seller Dimension\n",
    "facts.drop(['Seller Name', 'Seller Market', 'Seller Region', 'Seller Country', 'Seller State', 'Seller City'], axis=1, inplace=True)\n",
    "\n",
    "# Drop unnecessary columns from facts\n",
    "facts.drop(['City', 'State', 'Country', 'Region', 'Market'], axis=1, inplace=True)\n",
    "\n",
    "# Remove rows with specific customer names\n",
    "values_to_drop = ['Tom Zandusky', 'Cari MacIntyre', 'Kai Rey']\n",
    "facts = facts[~facts['Customer Name'].isin(values_to_drop)]\n",
    "\n",
    "# Map Customer Name to Customer Key\n",
    "customer_mapping = Customer_Dimension.set_index('Customer_Name')['Customer_Key'].to_dict()\n",
    "facts['Customer_Key'] = facts['Customer Name'].map(customer_mapping)\n",
    "\n",
    "# Map Order ID to Order Key\n",
    "order_mapping = Order_Information_Dimension.set_index('Order ID')['Order Key'].to_dict()\n",
    "facts['Order_Key'] = facts['Order ID'].map(order_mapping)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "facts.drop(['Customer ID', 'Customer Name', 'Segment', 'Order ID', 'Row ID', 'Ship Mode', 'Order Priority', 'Order Date', 'Ship Date'], axis=1, inplace=True)\n",
    "\n",
    "# Add Transaction Key column\n",
    "facts['Transaction_Key'] = range(1, len(facts) + 1)\n",
    "\n",
    "# Reorder columns\n",
    "desired_order = ['Transaction_Key', 'Product_Key', 'Customer_Key', 'Order_Key', 'Order_Date_Key', 'Ship_Date_Key', 'Seller Key', 'Sales', 'Quantity', 'Profit', 'Shipping Cost']\n",
    "Facts_Table = facts[desired_order]\n",
    "Facts_Table.rename(columns=lambda x: x.replace(' ', '_'), inplace=True)\n",
    "\n",
    "Facts_Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Facts_Table = Facts_Table.drop_duplicates(subset=['Product_Key', 'Customer_Key', 'Order_Key', 'Order_Date_Key', 'Ship_Date_Key', 'Seller_Key'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Table in DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check transaction status and perform rollback if necessary\n",
    "if conn.status == pg.extensions.STATUS_IN_TRANSACTION:\n",
    "    conn.rollback()\n",
    "\n",
    "# Create the facts table using the template\n",
    "sql_facts_table = \"\"\"\n",
    "    CREATE TABLE Facts_Table (\n",
    "        Transaction_Key NUMERIC(9,0),\n",
    "        Product_Key NUMERIC(9,0),\n",
    "        Customer_Key NUMERIC(9,0),\n",
    "        Order_Key NUMERIC(9,0),\n",
    "        Order_Date_Key NUMERIC(9,0),\n",
    "        Ship_Date_Key NUMERIC(9,0),\n",
    "        Seller_Key NUMERIC(9,0),\n",
    "        Sales NUMERIC(9,0),\n",
    "        Quantity NUMERIC(9,0),\n",
    "        Profit NUMERIC(9,0),\n",
    "        Shipping_Cost NUMERIC(9,0),\n",
    "    --\n",
    "        PRIMARY KEY (Product_Key, Customer_Key, Order_Key, Order_Date_Key, Ship_Date_Key, Seller_Key),\n",
    "    --\n",
    "        FOREIGN KEY (Product_Key) REFERENCES Product_Dimension(Product_Key),\n",
    "        FOREIGN KEY (Customer_Key) REFERENCES Customer_Dimension(Customer_Key),\n",
    "        FOREIGN KEY (Order_Key) REFERENCES Order_Information_Dimension(Order_Key),\n",
    "        FOREIGN KEY (Order_Date_Key) REFERENCES Order_Date_Dimension(Order_Date_Key),\n",
    "        FOREIGN KEY (Ship_Date_Key) REFERENCES Ship_Date_Dimension(Ship_Date_Key),\n",
    "        FOREIGN KEY (Seller_Key) REFERENCES Seller_Dimension(Seller_Key),\n",
    "    --\n",
    "        CHECK (Product_Key > 0),\n",
    "        CHECK (Customer_Key > 0),\n",
    "        CHECK (Order_Key > 0),\n",
    "        CHECK (Order_Date_Key > 0),\n",
    "        CHECK (Ship_Date_Key > 0),\n",
    "        CHECK (Seller_Key > 0)\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(\"DROP TABLE IF EXISTS Facts_Table;\")\n",
    "cursor.execute(sql_facts_table)\n",
    "conn.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Data into Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into DB\n",
    "Facts_Table_list = Facts_Table.to_numpy().tolist()\n",
    "\n",
    "sql_facts = \"\"\"\n",
    "INSERT INTO Facts_Table(Transaction_Key, Product_Key, Customer_Key, Order_Key, Order_Date_Key, Ship_Date_Key, Seller_Key, Sales, Quantity, Profit, Shipping_Cost)\n",
    "VALUES(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "\"\"\"\n",
    "\n",
    "cursor.executemany(sql_facts, Facts_Table_list)\n",
    "conn.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
