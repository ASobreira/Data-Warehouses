{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPAI Project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 1\n",
    "#### Tiago Rodrigues (49593)\n",
    "#### Ivo Oliveira (50301)\n",
    "#### Martim Silva (51304)\n",
    "#### Alexandre Sobreira (59451)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st Phase - Point 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orders (Main table)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Orders dataset the following steps were performed:\n",
    "- Read in the dataset\n",
    "- Convert Row ID and Quantity to integer data type\n",
    "- Convert Order ID, Customer ID, Customer Name, City, State, Country, Region, Market, Product ID and Product Name to string data type\n",
    "- Convert Ship Date and Order Date to date data type\n",
    "- Convert Segment, Category, Sub-Category and Order Priority to category data type\n",
    "- Drop the Postal Code column since it wont be used for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the dataset\n",
    "orders = pd.read_excel('../data/Raw_Tables/orders_RAW.xlsx')\n",
    "\n",
    "# Convert Row ID and Quantity to integer data type\n",
    "orders['Row ID'] = orders['Row ID'].astype(int)\n",
    "orders['Quantity'] = orders['Quantity'].astype(int)\n",
    "\n",
    "# Convert Order ID, Customer ID, Customer Name, City, State, Country, Region, Market, Product ID and Product Name to string data type\n",
    "orders['Order ID'] = orders['Order ID'].astype(str)\n",
    "orders['Customer ID'] = orders['Customer ID'].astype(str)\n",
    "orders['Customer Name'] = orders['Customer Name'].astype(str)\n",
    "orders['City'] = orders['City'].astype(str)\n",
    "orders['State'] = orders['State'].astype(str)\n",
    "orders['Country'] = orders['Country'].astype(str)\n",
    "orders['Region'] = orders['Region'].astype(str)\n",
    "orders['Market'] = orders['Market'].astype(str)\n",
    "orders['Product ID'] = orders['Product ID'].astype(str)\n",
    "orders['Product Name'] = orders['Product Name'].astype(str)\n",
    "\n",
    "# Convert Ship Date and Order Date to date data type\n",
    "orders['Ship Date'] = pd.to_datetime(orders['Ship Date'])\n",
    "orders['Order Date'] = pd.to_datetime(orders['Order Date'])\n",
    "\n",
    "# Convert Segment, Category, Sub-Category and Order Priority to category data type\n",
    "orders['Segment'] = orders['Segment'].astype('category')\n",
    "orders['Category'] = orders['Category'].astype('category')\n",
    "orders['Sub-Category'] = orders['Sub-Category'].astype('category')\n",
    "orders['Order Priority'] = orders['Order Priority'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = orders.drop('Postal Code', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51290 entries, 0 to 51289\n",
      "Data columns (total 23 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   Row ID          51290 non-null  int32         \n",
      " 1   Order ID        51290 non-null  object        \n",
      " 2   Order Date      51290 non-null  datetime64[ns]\n",
      " 3   Ship Date       51290 non-null  datetime64[ns]\n",
      " 4   Ship Mode       51290 non-null  object        \n",
      " 5   Customer ID     51290 non-null  object        \n",
      " 6   Customer Name   51290 non-null  object        \n",
      " 7   Segment         51290 non-null  category      \n",
      " 8   City            51290 non-null  object        \n",
      " 9   State           51290 non-null  object        \n",
      " 10  Country         51290 non-null  object        \n",
      " 11  Region          51290 non-null  object        \n",
      " 12  Market          51290 non-null  object        \n",
      " 13  Product ID      51290 non-null  object        \n",
      " 14  Category        51290 non-null  category      \n",
      " 15  Sub-Category    51290 non-null  category      \n",
      " 16  Product Name    51290 non-null  object        \n",
      " 17  Sales           51290 non-null  float64       \n",
      " 18  Quantity        51290 non-null  int32         \n",
      " 19  Discount        51290 non-null  float64       \n",
      " 20  Profit          51290 non-null  float64       \n",
      " 21  Shipping Cost   51290 non-null  float64       \n",
      " 22  Order Priority  51290 non-null  category      \n",
      "dtypes: category(4), datetime64[ns](2), float64(4), int32(2), object(11)\n",
      "memory usage: 7.2+ MB\n"
     ]
    }
   ],
   "source": [
    "orders.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "796"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many customers\n",
    "len(orders[\"Customer Name\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#orders.to_csv('orders_NEW.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customers Table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the customers_USA dataset the following steps were performed:\n",
    "- Read in the dataset\n",
    "- Convert Row ID and Quantity to integer data type\n",
    "- Convert Order ID, Customer ID, Customer Name, City, State, Country, Region, Market, Product ID and Product Name to string data type\n",
    "- Convert Ship Date and Order Date to date data type\n",
    "- Convert Segment, Category, Sub-Category and Order Priority to category data type\n",
    "- Drop the Postal Code column since it wont be used for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the dataset\n",
    "customers_USA = pd.read_csv('customers_USA.csv', encoding='latin1')\n",
    "\n",
    "# Convert Row ID and Quantity to integer data type\n",
    "customers_USA['Row ID'] = customers_USA['Row ID'].astype(int)\n",
    "customers_USA['Quantity'] = customers_USA['Quantity'].astype(int)\n",
    "\n",
    "# Convert Order ID, Customer ID, Customer Name, City, State, Country, Region, Market, Product ID and Product Name to string data type\n",
    "customers_USA['Order ID'] = customers_USA['Order ID'].astype(str)\n",
    "customers_USA['Customer ID'] = customers_USA['Customer ID'].astype(str)\n",
    "customers_USA['Customer Name'] = customers_USA['Customer Name'].astype(str)\n",
    "customers_USA['City'] = customers_USA['City'].astype(str)\n",
    "customers_USA['State'] = customers_USA['State'].astype(str)\n",
    "customers_USA['Country'] = customers_USA['Country'].astype(str)\n",
    "customers_USA['Region'] = customers_USA['Region'].astype(str)\n",
    "customers_USA['Product ID'] = customers_USA['Product ID'].astype(str)\n",
    "customers_USA['Product Name'] = customers_USA['Product Name'].astype(str)\n",
    "\n",
    "# Convert Ship Date and Order Date to date data type\n",
    "customers_USA['Ship Date'] = pd.to_datetime(customers_USA['Ship Date'])\n",
    "customers_USA['Order Date'] = pd.to_datetime(customers_USA['Order Date'])\n",
    "\n",
    "# Convert Segment, Category, Sub-Category and Order Priority to category data type\n",
    "customers_USA['Segment'] = customers_USA['Segment'].astype('category')\n",
    "customers_USA['Category'] = customers_USA['Category'].astype('category')\n",
    "customers_USA['Sub-Category'] = customers_USA['Sub-Category'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#customers_USA.to_csv('customers_USA_NEW.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9994 entries, 0 to 9993\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   Row ID         9994 non-null   int32         \n",
      " 1   Order ID       9994 non-null   object        \n",
      " 2   Order Date     9994 non-null   datetime64[ns]\n",
      " 3   Ship Date      9994 non-null   datetime64[ns]\n",
      " 4   Ship Mode      9994 non-null   object        \n",
      " 5   Customer ID    9994 non-null   object        \n",
      " 6   Customer Name  9994 non-null   object        \n",
      " 7   Segment        9994 non-null   category      \n",
      " 8   Country        9994 non-null   object        \n",
      " 9   City           9994 non-null   object        \n",
      " 10  State          9994 non-null   object        \n",
      " 11  Postal Code    9994 non-null   int64         \n",
      " 12  Region         9994 non-null   object        \n",
      " 13  Product ID     9994 non-null   object        \n",
      " 14  Category       9994 non-null   category      \n",
      " 15  Sub-Category   9994 non-null   category      \n",
      " 16  Product Name   9994 non-null   object        \n",
      " 17  Sales          9994 non-null   float64       \n",
      " 18  Quantity       9994 non-null   int32         \n",
      " 19  Discount       9994 non-null   float64       \n",
      " 20  Profit         9994 non-null   float64       \n",
      "dtypes: category(3), datetime64[ns](2), float64(3), int32(2), int64(1), object(10)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "customers_USA.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returns Table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Returns dataset the following steps were performed:\n",
    "- Read in the dataset\n",
    "- Convert Order ID and Region to string data type\n",
    "- Convert Returned column to a boolean data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1079 entries, 0 to 1078\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Returned  1079 non-null   bool  \n",
      " 1   Order ID  1079 non-null   object\n",
      " 2   Region    1079 non-null   object\n",
      "dtypes: bool(1), object(2)\n",
      "memory usage: 18.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Read in the dataset\n",
    "returns = pd.read_csv('returns.csv', encoding='latin1')\n",
    "\n",
    "# Convert Order ID and Region to string data type\n",
    "returns['Order ID'] = returns['Order ID'].astype(str)\n",
    "returns['Region'] = returns['Region'].astype(str)\n",
    "\n",
    "# Convert Returned column to a boolean data type\n",
    "returns['Returned'] = returns['Returned'].map({'Yes': True, 'No': False})\n",
    "returns['Returned'] = returns['Returned'].astype(bool)\n",
    "returns.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns.to_csv('returns_NEW.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sellers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Sellers dataset the following steps were performed:\n",
    "- Read in the dataset\n",
    "- Convert Person and Region to string data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1079 entries, 0 to 1078\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Returned  1079 non-null   bool  \n",
      " 1   Order ID  1079 non-null   object\n",
      " 2   Region    1079 non-null   object\n",
      "dtypes: bool(1), object(2)\n",
      "memory usage: 18.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Read in the dataset\n",
    "sellers = pd.read_csv('sellers.csv', delimiter=';')\n",
    "\n",
    "# Convert Person and Region to string data type\n",
    "sellers['Person'] = sellers['Person'].astype(str)\n",
    "sellers['Region'] = sellers['Region'].astype(str)\n",
    "\n",
    "returns.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sellers.to_csv('sellers_NEW.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GDP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the GDP_USA dataset the following steps were performed:\n",
    "- Read in the dataset\n",
    "- Filter out all entries where the state is either Alaska or Hawaii\n",
    "- Remove Region, SUB-REGION, County columns\n",
    "- Filter the years that are not between 2012 and 2015\n",
    "- Convert Year to an integer date type\n",
    "- Calculate the mean and sum of the GDP values for each state and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alabama</th>\n",
       "      <td>2.800666e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <td>1.820583e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arkansas</th>\n",
       "      <td>1.491023e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>3.925574e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colorado</th>\n",
       "      <td>4.532296e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Connecticut</th>\n",
       "      <td>3.017599e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delaware</th>\n",
       "      <td>2.087840e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>District of Columbia</th>\n",
       "      <td>1.143905e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>1.193218e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Georgia</th>\n",
       "      <td>2.896556e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idaho</th>\n",
       "      <td>1.375440e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>7.169497e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indiana</th>\n",
       "      <td>3.333621e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iowa</th>\n",
       "      <td>1.637191e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kansas</th>\n",
       "      <td>1.358419e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kentucky</th>\n",
       "      <td>1.493476e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Louisiana</th>\n",
       "      <td>3.619598e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maine</th>\n",
       "      <td>3.321592e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maryland</th>\n",
       "      <td>1.410144e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Massachusetts</th>\n",
       "      <td>3.239691e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michigan</th>\n",
       "      <td>5.172281e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minnesota</th>\n",
       "      <td>3.497891e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mississippi</th>\n",
       "      <td>1.218117e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Missouri</th>\n",
       "      <td>2.370631e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Montana</th>\n",
       "      <td>7.699758e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nebraska</th>\n",
       "      <td>1.142196e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nevada</th>\n",
       "      <td>7.668025e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Hampshire</th>\n",
       "      <td>6.938747e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Jersey</th>\n",
       "      <td>2.505048e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Mexico</th>\n",
       "      <td>2.686694e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>2.162467e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Carolina</th>\n",
       "      <td>4.523661e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Dakota</th>\n",
       "      <td>1.015083e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>6.376435e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oklahoma</th>\n",
       "      <td>2.385888e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>5.029293e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pennsylvania</th>\n",
       "      <td>9.852809e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rhode Island</th>\n",
       "      <td>1.044762e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Carolina</th>\n",
       "      <td>3.955402e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Dakota</th>\n",
       "      <td>6.690601e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tennessee</th>\n",
       "      <td>3.062775e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>5.908473e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>4.640777e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vermont</th>\n",
       "      <td>2.050231e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virginia</th>\n",
       "      <td>3.179555e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington</th>\n",
       "      <td>1.078327e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Virginia</th>\n",
       "      <td>1.268995e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wisconsin</th>\n",
       "      <td>3.888268e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wyoming</th>\n",
       "      <td>1.688115e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              mean\n",
       "State                             \n",
       "Alabama               2.800666e+09\n",
       "Arizona               1.820583e+10\n",
       "Arkansas              1.491023e+09\n",
       "California            3.925574e+10\n",
       "Colorado              4.532296e+09\n",
       "Connecticut           3.017599e+10\n",
       "Delaware              2.087840e+10\n",
       "District of Columbia  1.143905e+11\n",
       "Florida               1.193218e+10\n",
       "Georgia               2.896556e+09\n",
       "Idaho                 1.375440e+09\n",
       "Illinois              7.169497e+09\n",
       "Indiana               3.333621e+09\n",
       "Iowa                  1.637191e+09\n",
       "Kansas                1.358419e+09\n",
       "Kentucky              1.493476e+09\n",
       "Louisiana             3.619598e+09\n",
       "Maine                 3.321592e+09\n",
       "Maryland              1.410144e+10\n",
       "Massachusetts         3.239691e+10\n",
       "Michigan              5.172281e+09\n",
       "Minnesota             3.497891e+09\n",
       "Mississippi           1.218117e+09\n",
       "Missouri              2.370631e+09\n",
       "Montana               7.699758e+08\n",
       "Nebraska              1.142196e+09\n",
       "Nevada                7.668025e+09\n",
       "New Hampshire         6.938747e+09\n",
       "New Jersey            2.505048e+10\n",
       "New Mexico            2.686694e+09\n",
       "New York              2.162467e+10\n",
       "North Carolina        4.523661e+09\n",
       "North Dakota          1.015083e+09\n",
       "Ohio                  6.376435e+09\n",
       "Oklahoma              2.385888e+09\n",
       "Oregon                5.029293e+09\n",
       "Pennsylvania          9.852809e+09\n",
       "Rhode Island          1.044762e+10\n",
       "South Carolina        3.955402e+09\n",
       "South Dakota          6.690601e+08\n",
       "Tennessee             3.062775e+09\n",
       "Texas                 5.908473e+09\n",
       "Utah                  4.640777e+09\n",
       "Vermont               2.050231e+09\n",
       "Virginia              3.179555e+09\n",
       "Washington            1.078327e+10\n",
       "West Virginia         1.268995e+09\n",
       "Wisconsin             3.888268e+09\n",
       "Wyoming               1.688115e+09"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the dataset\n",
    "gdp = pd.read_csv(\"../data/Raw_Tables/GDP_USA_RAW.csv\", delimiter=\",\", encoding=\"windows-1252\")\n",
    "\n",
    "# Filter out all entries where the state is either Alaska or Hawaii.\n",
    "gdp = gdp[(gdp['State'] != \"Alaska\") & (gdp['State'] != \"Hawaii\")]\n",
    "\n",
    "# Remove Region, SUB-REGION, County columns\n",
    "gdp.drop(['Region','SUB_REGION','County'], axis = 1, inplace = True)\n",
    "\n",
    "# Filter the years that are not between 2012 and 2015\n",
    "gdp = gdp[gdp['Year'].isin([2012, 2013, 2014, 2015])]\n",
    "\n",
    "# Convert Year to an integer date type\n",
    "gdp['Year'] = pd.to_datetime(gdp['Year'], format='%Y') \n",
    "\n",
    "# Calculate the mean and sum of the GDP values for each state and year\n",
    "result = gdp.groupby(['State'])['GDP (Chained $)'].agg(['mean'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2012-01-01T00:00:00.000000000', '2014-01-01T00:00:00.000000000',\n",
       "       '2015-01-01T00:00:00.000000000', '2013-01-01T00:00:00.000000000'],\n",
       "      dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdp[\"Year\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot insert level_0, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\afbso\\OneDrive - Universidade de Lisboa\\MCD\\2º Semestre\\I.P.A.I\\IPAI_project\\Phase01\\data\\phase01_point02.ipynb Cell 28\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/afbso/OneDrive%20-%20Universidade%20de%20Lisboa/MCD/2%C2%BA%20Semestre/I.P.A.I/IPAI_project/Phase01/data/phase01_point02.ipynb#X51sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39;49mreset_index()\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mMean\u001b[39m\u001b[39m'\u001b[39m})\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/afbso/OneDrive%20-%20Universidade%20de%20Lisboa/MCD/2%C2%BA%20Semestre/I.P.A.I/IPAI_project/Phase01/data/phase01_point02.ipynb#X51sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m result \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(result)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/afbso/OneDrive%20-%20Universidade%20de%20Lisboa/MCD/2%C2%BA%20Semestre/I.P.A.I/IPAI_project/Phase01/data/phase01_point02.ipynb#X51sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m result\n",
      "File \u001b[1;32mc:\\Users\\afbso\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\afbso\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:5839\u001b[0m, in \u001b[0;36mDataFrame.reset_index\u001b[1;34m(self, level, drop, inplace, col_level, col_fill)\u001b[0m\n\u001b[0;32m   5833\u001b[0m         \u001b[39mif\u001b[39;00m lab \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5834\u001b[0m             \u001b[39m# if we have the codes, extract the values with a mask\u001b[39;00m\n\u001b[0;32m   5835\u001b[0m             level_values \u001b[39m=\u001b[39m algorithms\u001b[39m.\u001b[39mtake(\n\u001b[0;32m   5836\u001b[0m                 level_values, lab, allow_fill\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, fill_value\u001b[39m=\u001b[39mlev\u001b[39m.\u001b[39m_na_value\n\u001b[0;32m   5837\u001b[0m             )\n\u001b[1;32m-> 5839\u001b[0m         new_obj\u001b[39m.\u001b[39;49minsert(\u001b[39m0\u001b[39;49m, name, level_values)\n\u001b[0;32m   5841\u001b[0m new_obj\u001b[39m.\u001b[39mindex \u001b[39m=\u001b[39m new_index\n\u001b[0;32m   5842\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m inplace:\n",
      "File \u001b[1;32mc:\\Users\\afbso\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4440\u001b[0m, in \u001b[0;36mDataFrame.insert\u001b[1;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[0;32m   4434\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   4435\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot specify \u001b[39m\u001b[39m'\u001b[39m\u001b[39mallow_duplicates=True\u001b[39m\u001b[39m'\u001b[39m\u001b[39m when \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   4436\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mself.flags.allows_duplicate_labels\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is False.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   4437\u001b[0m     )\n\u001b[0;32m   4438\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_duplicates \u001b[39mand\u001b[39;00m column \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns:\n\u001b[0;32m   4439\u001b[0m     \u001b[39m# Should this be a different kind of error??\u001b[39;00m\n\u001b[1;32m-> 4440\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcannot insert \u001b[39m\u001b[39m{\u001b[39;00mcolumn\u001b[39m}\u001b[39;00m\u001b[39m, already exists\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   4441\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(loc, \u001b[39mint\u001b[39m):\n\u001b[0;32m   4442\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mloc must be int\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot insert level_0, already exists"
     ]
    }
   ],
   "source": [
    "result = result.reset_index().rename(columns={'mean': 'Mean'})\n",
    "result = pd.DataFrame(result)\n",
    "result = result.drop(columns=['level_0', 'index'])\n",
    "result['Mean'] = result['Mean'].round(3)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2.800666e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>1.820583e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>1.491023e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>California</td>\n",
       "      <td>3.925574e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>4.532296e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>3.017599e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>2.087840e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>1.143905e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Florida</td>\n",
       "      <td>1.193218e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>2.896556e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>1.375440e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>7.169497e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>3.333621e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>1.637191e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>1.358419e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>1.493476e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>3.619598e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Maine</td>\n",
       "      <td>3.321592e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>1.410144e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>3.239691e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>5.172281e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>3.497891e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>1.218117e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>2.370631e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Montana</td>\n",
       "      <td>7.699758e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Nebraska</td>\n",
       "      <td>1.142196e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>7.668025e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>6.938747e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>New Jersey</td>\n",
       "      <td>2.505048e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New Mexico</td>\n",
       "      <td>2.686694e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>New York</td>\n",
       "      <td>2.162467e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>4.523661e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>North Dakota</td>\n",
       "      <td>1.015083e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>6.376435e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>2.385888e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Oregon</td>\n",
       "      <td>5.029293e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>9.852809e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>1.044762e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>South Carolina</td>\n",
       "      <td>3.955402e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>6.690601e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>3.062775e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Texas</td>\n",
       "      <td>5.908473e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Utah</td>\n",
       "      <td>4.640777e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>2.050231e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>3.179555e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Washington</td>\n",
       "      <td>1.078327e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>1.268995e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>3.888268e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>1.688115e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   State          Mean\n",
       "0                Alabama  2.800666e+09\n",
       "1                Arizona  1.820583e+10\n",
       "2               Arkansas  1.491023e+09\n",
       "3             California  3.925574e+10\n",
       "4               Colorado  4.532296e+09\n",
       "5            Connecticut  3.017599e+10\n",
       "6               Delaware  2.087840e+10\n",
       "7   District of Columbia  1.143905e+11\n",
       "8                Florida  1.193218e+10\n",
       "9                Georgia  2.896556e+09\n",
       "10                 Idaho  1.375440e+09\n",
       "11              Illinois  7.169497e+09\n",
       "12               Indiana  3.333621e+09\n",
       "13                  Iowa  1.637191e+09\n",
       "14                Kansas  1.358419e+09\n",
       "15              Kentucky  1.493476e+09\n",
       "16             Louisiana  3.619598e+09\n",
       "17                 Maine  3.321592e+09\n",
       "18              Maryland  1.410144e+10\n",
       "19         Massachusetts  3.239691e+10\n",
       "20              Michigan  5.172281e+09\n",
       "21             Minnesota  3.497891e+09\n",
       "22           Mississippi  1.218117e+09\n",
       "23              Missouri  2.370631e+09\n",
       "24               Montana  7.699758e+08\n",
       "25              Nebraska  1.142196e+09\n",
       "26                Nevada  7.668025e+09\n",
       "27         New Hampshire  6.938747e+09\n",
       "28            New Jersey  2.505048e+10\n",
       "29            New Mexico  2.686694e+09\n",
       "30              New York  2.162467e+10\n",
       "31        North Carolina  4.523661e+09\n",
       "32          North Dakota  1.015083e+09\n",
       "33                  Ohio  6.376435e+09\n",
       "34              Oklahoma  2.385888e+09\n",
       "35                Oregon  5.029293e+09\n",
       "36          Pennsylvania  9.852809e+09\n",
       "37          Rhode Island  1.044762e+10\n",
       "38        South Carolina  3.955402e+09\n",
       "39          South Dakota  6.690601e+08\n",
       "40             Tennessee  3.062775e+09\n",
       "41                 Texas  5.908473e+09\n",
       "42                  Utah  4.640777e+09\n",
       "43               Vermont  2.050231e+09\n",
       "44              Virginia  3.179555e+09\n",
       "45            Washington  1.078327e+10\n",
       "46         West Virginia  1.268995e+09\n",
       "47             Wisconsin  3.888268e+09\n",
       "48               Wyoming  1.688115e+09"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gdp.to_csv('GDP_USA_NEW.csv', index=False)\n",
    "#result.to_csv('AVG_GDP_USA_NEW.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holidays"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the holiday_USA dataset the following steps were performed:\n",
    "- Read in the dataset\n",
    "- Filter the years that are not between 2012 and 2015\n",
    "- Convert the column Date to a date data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 76 entries, 8 to 339\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Date     76 non-null     object\n",
      " 1   Holiday  76 non-null     object\n",
      " 2   WeekDay  76 non-null     object\n",
      " 3   Month    76 non-null     int64 \n",
      " 4   Day      76 non-null     int64 \n",
      " 5   Year     76 non-null     int64 \n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 4.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Read in the dataset\n",
    "holiday = pd.read_csv(\"../data/Raw_Tables/holiday_USA_RAW.csv\", delimiter=\",\", encoding=\"windows-1252\")\n",
    "\n",
    "# Filter the years that are not between 2012 and 2015\n",
    "holiday = holiday[holiday['Year'].isin([2012, 2013, 2014, 2015])]\n",
    "\n",
    "# Convert the column Date to a date data type\n",
    "holiday['Date'] = pd.to_datetime(holiday['Date'], format='%Y-%m-%d')\n",
    "holiday['Date'] = holiday['Date'].dt.strftime('%d-%m-%Y')\n",
    "\n",
    "# Correct  \" New Yearâ€™s Eve \" & \" Valentineâ€™s Day \" \n",
    "holiday[\"Holiday\"] = holiday[\"Holiday\"].replace({\n",
    "    \"New Yearâ€™s Eve\": \"New Years Eve\",\n",
    "    \"Valentineâ€™s Day\": \"Valentines Day\"\n",
    "})\n",
    "\n",
    "holiday.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday.to_csv('holiday_USA_NEW.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
